# Informe Ejecutivo y Pedag贸gico - Aurelion ML Sprint 3

##  1. Resultados del Modelo (M茅tricas)

| M茅trica | Valor | Interpretaci贸n |
|---------|-------|----------------|
| **Accuracy** | 100% | El modelo clasific贸 correctamente todos los casos del set de prueba. |
| **Precision** | 1.00 | De todos los clientes identificados como "Fieles", el 100% realmente lo eran. |
| **Recall** | 1.00 | El modelo encontr贸 al 100% de los clientes fieles; no se le escap贸 ninguno. |

> **Nota:** Un resultado de 100% es posible aqu铆 porque la regla de negocio es determin铆stica (Frecuencia >= 2). En datos reales con ruido, esperamos valores entre 85-95%.

---

## М 2. Matriz de Confusi贸n (Explicaci贸n)

Para defender tu gr谩fico ante el profesor:

*   **TP (Verdadero Positivo):** La IA predijo "Fiel" y acert贸. (Ganancia).
*   **TN (Verdadero Negativo):** La IA predijo "Ocasional" y acert贸. (Ahorro).
*   **FP (Falso Positivo):** La IA predijo "Fiel" pero se equivoc贸. (Desperdicio de Marketing).
*   **FN (Falso Negativo):** La IA predijo "Ocasional" pero se equivoc贸. (P茅rdida de Cliente).

---

##  3. Resumen Pedag贸gico (Herramientas y Proceso)

###  Herramientas Utilizadas
*   **Lenguaje:** Python 3.8+
*   **Biblioteca Principal:** Scikit-Learn (sklearn)
*   **Manipulaci贸n de Datos:** Pandas
*   **Algoritmo:** Regresi贸n Log铆stica (LogisticRegression)

### 锔 Configuraci贸n del Entrenamiento
*   **Tasa de Aprendizaje (Learning Rate):** 0.01. Define qu茅 tan r谩pido "aprende" el modelo. Un valor bajo evita que el modelo oscile.
*   **Iteraciones:** 100. Cantidad de veces que el algoritmo revis贸 los datos completos para ajustar sus pesos.
*   **Optimizador:** 'liblinear'. Eficiente para datasets peque帽os como el de Aurelion.

---

##  4. Preguntas de Defensa (Deep Dive)

**P: 驴Qu茅 son las Iteraciones?**
R: Imagina leer un libro de texto. Leerlo entero una vez es 1 Iteraci贸n. Aqu铆, el modelo ley贸 los datos 100 veces.
*   **驴C贸mo calcularlas?** No se adivina. Se usa una t茅cnica llamada "Early Stopping": entrenar hasta que el error deje de bajar. Si son pocas, el modelo no aprende (Underfitting). Si son demasiadas, memoriza ruido (Overfitting).

**P: 驴Qu茅 es el Optimizador (y por qu茅 liblinear)?**
R: Es el motor matem谩tico que busca el m铆nimo error (como encontrar el camino para bajar una monta帽a). Usamos 'liblinear' porque es el est谩ndar recomendado para datasets peque帽os y clasificaci贸n binaria.

**P: 驴Por qu茅 la curva es una "S" (Sigmoide)?**
R: Porque predecimos **Probabilidad** (0 a 1). Una l铆nea recta (Regresi贸n Lineal) podr铆a dar valores como 1.5 o -0.2, lo cual es imposible. La funci贸n Sigmoide "aplasta" cualquier valor para que siempre quede entre 0% y 100%.

**P: 驴Por qu茅 Regresi贸n Log铆stica y no Lineal?**
R: La Lineal predice valores continuos (Precios). La Log铆stica clasifica categor铆as (S铆/No).

---

##  5. Conclusi贸n de Negocio (Ejecutivo)

**Hallazgo:** 
El modelo ha confirmado matem谩ticamente que la variable **Frecuencia** es el predictor determinante de la lealtad. No importa tanto el gasto total inicial, sino el acto de regresar a la tienda.

**Recomendaci贸n Estrat茅gica:**
Aurelion debe dejar de invertir en clientes que compran una sola vez grandes montos (Ruido) y enfocar su presupuesto en incentivar la **segunda compra** (ej. Cup贸n de 20% para la visita #2), ya que esto dispara la probabilidad de fidelidad al 100%.
