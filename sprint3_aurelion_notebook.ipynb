{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Proyecto Aurelion - Sprint 3\n",
        "## Modelo de Clasificaci√≥n de Fidelidad\n",
        "\n",
        "Este notebook ejecuta el entrenamiento del modelo de Regresi√≥n Log√≠stica utilizando los datos procesados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# PROYECTO AURELION - SPRINT 3: CLASIFICACI√ìN DE FIDELIDAD (MACHINE LEARNING)\n",
        "# VERSI√ìN: 1.3 (Compatible con VS Code)\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "print(\"üöÄ Iniciando Script de Entrenamiento Aurelion...\")\n",
        "\n",
        "# 1. CARGA DE DATOS\n",
        "# ------------------------------------------------------------------------------\n",
        "# Intentamos cargar el archivo CSV generado por la App.\n",
        "# Aseg√∫rate de que 'master_rfm_aurelion_limpio.csv' est√© en la misma carpeta que este script.\n",
        "\n",
        "filename = 'master_rfm_aurelion_limpio.csv'\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"‚úÖ Dataset '{filename}' cargado exitosamente. Registros: {len(df)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå ERROR CR√çTICO: No se encontr√≥ el archivo '{filename}'.\")\n",
        "    print(\"   -> Por favor, ve a la secci√≥n 'Ingenier√≠a Features' de la App y descarga el CSV.\")\n",
        "    # Creamos un dataset dummy peque√±o solo para que el c√≥digo no rompa si lo pruebas sin archivo\n",
        "    print(\"‚ö†Ô∏è Generando datos de prueba TEMPORALES para demostraci√≥n...\")\n",
        "    data = {\n",
        "        'id_cliente': range(1, 21),\n",
        "        'recency_days': np.random.randint(1, 100, 20),\n",
        "        'frequency': np.random.randint(1, 5, 20),\n",
        "        'monetary_log': np.random.rand(20) * 5,\n",
        "        'ciudad': np.random.choice(['Cordoba', 'Villa Maria', 'Carlos Paz'], 20),\n",
        "        'categoria_preferida': np.random.choice(['Alimentos', 'Limpieza'], 20),\n",
        "        'is_fidelizado': np.random.randint(0, 2, 20)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "# 2. DEFINICI√ìN DEL TARGET (Y)\n",
        "# ------------------------------------------------------------------------------\n",
        "# La columna 'is_fidelizado' ya viene calculada desde la App (Regla: Frequency >= 2).\n",
        "# Si quisieras recalcularla en Python, ser√≠a:\n",
        "# df['is_fidelizado'] = (df['frequency'] >= 2).astype(int)\n",
        "\n",
        "# 3. PREPARACI√ìN DEL MODELO (PIPELINE)\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"‚öôÔ∏è Preparando Pipeline de Preprocesamiento...\")\n",
        "\n",
        "# Definimos columnas\n",
        "numerical_features = ['recency_days', 'frequency', 'monetary_log']\n",
        "categorical_features = ['ciudad', 'categoria_preferida']\n",
        "\n",
        "# Transformadores\n",
        "# StandardScaler: Normaliza los n√∫meros (Media 0, Desv 1) para que el modelo converja mejor.\n",
        "# OneHotEncoder: Convierte categor√≠as (Texto) en columnas binarias (0/1).\n",
        "numerical_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore', drop='first')\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Pipeline: Une preprocesamiento + Modelo\n",
        "# Usamos Regresi√≥n Log√≠stica con el optimizador 'liblinear' (ideal para datasets peque√±os)\n",
        "model_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=42, solver='liblinear', max_iter=100))\n",
        "])\n",
        "\n",
        "# 4. ENTRENAMIENTO\n",
        "# ------------------------------------------------------------------------------\n",
        "X = df[numerical_features + categorical_features]\n",
        "y = df['is_fidelizado']\n",
        "\n",
        "# Divisi√≥n: 70% para Entrenar, 30% para Testear (Examen)\n",
        "# stratify=y asegura que haya proporciones iguales de Fieles/Ocasionales en ambos sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "print(\"üß† Entrenando modelo (LogisticRegression)...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "print(\"‚úÖ Modelo entrenado exitosamente.\")\n",
        "\n",
        "# 5. EVALUACI√ìN\n",
        "# ------------------------------------------------------------------------------\n",
        "print(\"\\nüìä EVALUACI√ìN DEL MODELO:\")\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "\n",
        "print(\"Matriz de Confusi√≥n:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nReporte de Clasificaci√≥n:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"üèÅ Proceso finalizado.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}